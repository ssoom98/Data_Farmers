{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96f0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일별 품목명:\n",
      "file\n",
      "감자_cleaned.csv                                       [수미]\n",
      "고구마_cleaned.csv                             [밤고구마, 호박고구마]\n",
      "깐마늘_통합_최종_데이터.csv                                [깐마늘_통합]\n",
      "깻잎_cleaned.csv                                   [깻잎(일반)]\n",
      "느타리버섯_cleaned.csv         [느타리버섯(일반), 맛느타리버섯, 애느타리버섯(일반)]\n",
      "단호박_cleaned.csv                                     [단호박]\n",
      "당근_cleaned.csv                                   [당근(일반)]\n",
      "미나리_cleaned.csv                           [돌미나리, 미나리(일반)]\n",
      "부추_cleaned.csv                               [영양부추, 일반부추]\n",
      "브로콜리_cleaned.csv                [뉴그린, 브로코리(국산), 브로코리(일반)]\n",
      "새송이버섯_cleaned.csv                               [새송이(일반)]\n",
      "시금치_cleaned.csv                                 [시금치(일반)]\n",
      "애호박_cleaned.csv                              [애호박, 쥬키니호박]\n",
      "양배추_cleaned.csv                        [양배추(수입), 양배추(일반)]\n",
      "양상추_cleaned.csv                        [양상추(수입), 양상추(일반)]\n",
      "양송이버섯_cleaned.csv                               [양송이(일반)]\n",
      "양파_cleaned.csv                          [깐양파, 만생양파, 자주양파]\n",
      "오이_cleaned.csv                         [백다다기, 오이(일반), 취청]\n",
      "적양배추_filtered.csv                                [적채(일반)]\n",
      "쪽파_cleaned.csv                        [깐쪽파, 쪽파(일반), 포장쪽파]\n",
      "청고추(풋고추)_통합_최종_데이터.csv                           [풋고추_통합]\n",
      "청고추_머지제외.csv                      [녹광, 오이맛고추, 청양, 청초(일반)]\n",
      "치커리_cleaned.csv                      [레드치커리, 치커리(일반), 치콘]\n",
      "토마토전체_cleaned.csv           [대추방울, 방울토마토, 완숙토마토, 토마토(일반)]\n",
      "파프리카_머지제외.csv                            [노랑파프리카, 빨강파프리카]\n",
      "파프리카녹색_통합_최종_데이터.csv                          [녹색파프리카_통합]\n",
      "팽이버섯_cleaned.csv                                     [팽이]\n",
      "표고버섯_cleaned.csv                     [생표고(수입)　, 표고버섯(일반)]\n",
      "피망전체_cleaned.csv                               [청피망, 홍피망]\n",
      "홍고추_cleaned.csv                            [홍고추(일반), 홍청양]\n",
      "Name: 품목명, dtype: object\n",
      "\n",
      "전체 품목명 (중복 제거):\n",
      "['깐마늘_통합', '깐양파', '깐쪽파', '깻잎(일반)', '노랑파프리카', '녹광', '녹색파프리카_통합', '뉴그린', '느타리버섯(일반)', '단호박', '당근(일반)', '대추방울', '돌미나리', '레드치커리', '만생양파', '맛느타리버섯', '미나리(일반)', '밤고구마', '방울토마토', '백다다기', '브로코리(국산)', '브로코리(일반)', '빨강파프리카', '새송이(일반)', '생표고(수입)\\u3000', '수미', '시금치(일반)', '애느타리버섯(일반)', '애호박', '양배추(수입)', '양배추(일반)', '양상추(수입)', '양상추(일반)', '양송이(일반)', '영양부추', '오이(일반)', '오이맛고추', '완숙토마토', '일반부추', '자주양파', '적채(일반)', '쥬키니호박', '쪽파(일반)', '청양', '청초(일반)', '청피망', '취청', '치커리(일반)', '치콘', '토마토(일반)', '팽이', '포장쪽파', '표고버섯(일반)', '풋고추_통합', '호박고구마', '홍고추(일반)', '홍청양', '홍피망']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 경로 설정 ----------\n",
    "FOLDER = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종\")\n",
    "\n",
    "# ---------- CSV 불러오기 & 품목명 추출 ----------\n",
    "all_items = []\n",
    "\n",
    "for f in sorted(FOLDER.glob(\"*.csv\")):\n",
    "    try:\n",
    "        df = pd.read_csv(f, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(f, encoding=\"cp949\")\n",
    "    \n",
    "    # '품목명' 컬럼이 있으면 수집\n",
    "    if \"품목명\" in df.columns:\n",
    "        unique_items = df[\"품목명\"].dropna().unique().tolist()\n",
    "        for item in unique_items:\n",
    "            all_items.append({\"file\": f.name, \"품목명\": item})\n",
    "    else:\n",
    "        print(f\"[경고] '{f.name}' 파일에는 '품목명' 컬럼이 없습니다.\")\n",
    "\n",
    "# ---------- 결과 정리 ----------\n",
    "if all_items:  # 하나라도 있으면 DataFrame 변환\n",
    "    result_df = pd.DataFrame(all_items)\n",
    "\n",
    "    # 파일별 품목명 리스트\n",
    "    print(\"파일별 품목명:\")\n",
    "    print(result_df.groupby(\"file\")[\"품목명\"].apply(list))\n",
    "\n",
    "    # 전체 unique 품목명\n",
    "    print(\"\\n전체 품목명 (중복 제거):\")\n",
    "    print(sorted(result_df[\"품목명\"].unique()))\n",
    "\n",
    "    # 저장\n",
    "    result_df.to_csv(FOLDER / \"품목명_모음.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "else:\n",
    "    print(\"⚠️ 어떤 파일에서도 '품목명' 컬럼을 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a81ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 느타리버섯_cleaned(애느타리).csv → 느타리버섯_cleaned(애느타리)_drop_애느타리버섯일반.csv 저장 (총 10626행 → 7084행, 드랍 3542행: '애느타리버섯(일반)')\n",
      "✅ 브로콜리_(일반제외).csv → 브로콜리_(일반제외)_drop_브로콜리일반.csv 저장 (총 10626행 → 10626행, 드랍 0행: '브로콜리(일반)')\n",
      "✅ 오이_cleaned.csv → 오이_cleaned_drop_오이일반.csv 저장 (총 10626행 → 7084행, 드랍 3542행: '오이(일반)')\n",
      "✅ 표고버섯_cleaned.csv → 표고버섯_cleaned_drop_생표고수입.csv 저장 (총 7084행 → 7084행, 드랍 0행: '생표고(수입)')\n",
      "\n",
      "생성된 파일:\n",
      " - 느타리버섯_cleaned(애느타리)_drop_애느타리버섯일반.csv\n",
      " - 브로콜리_(일반제외)_drop_브로콜리일반.csv\n",
      " - 오이_cleaned_drop_오이일반.csv\n",
      " - 표고버섯_cleaned_drop_생표고수입.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# ===== 경로 설정 =====\n",
    "FOLDER = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종\")\n",
    "\n",
    "# ===== 처리 규칙: {파일키워드: 드랍할 품목명} =====\n",
    "rules = {\n",
    "    \"느타리버섯\": \"애느타리버섯(일반)\",   # 1) 느타리버섯 CSV에서 드랍\n",
    "    \"브로콜리\":   \"브로콜리(일반)\",       # 2) 브로콜리 CSV에서 드랍\n",
    "    \"오이\":       \"오이(일반)\",           # 3) 오이 CSV에서 드랍\n",
    "    \"표고버섯\":   \"생표고(수입)\"          # 4) 표고버섯 CSV에서 드랍\n",
    "}\n",
    "\n",
    "def find_csv_by_keyword(folder: Path, keyword: str) -> Path | None:\n",
    "    \"\"\"폴더 내에서 파일명에 keyword가 포함된 CSV를 우선순위 규칙으로 선택.\"\"\"\n",
    "    cand = [p for p in folder.glob(\"*.csv\") if keyword in p.stem]\n",
    "    if not cand:\n",
    "        return None\n",
    "    # 우선순위: 'cleaned' 포함 > 파일명 짧은 순\n",
    "    cand.sort(key=lambda p: ( \"cleaned\" not in p.stem, len(p.name) ))\n",
    "    return cand[0]\n",
    "\n",
    "def read_csv_safely(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp949\")\n",
    "\n",
    "def sanitize_filename_piece(s: str) -> str:\n",
    "    # 파일명에 쓰기 안전하도록 한글/영문/숫자/언더스코어/하이픈만 남김\n",
    "    out = re.sub(r\"[^\\w\\-가-힣]\", \"\", s)\n",
    "    return out[:50]  # 너무 길면 살짝 자르기\n",
    "\n",
    "created = []\n",
    "\n",
    "for keyword, drop_value in rules.items():\n",
    "    src = find_csv_by_keyword(FOLDER, keyword)\n",
    "    if src is None:\n",
    "        print(f\"⚠️ '{keyword}' 키워드로 CSV를 찾지 못했습니다.\")\n",
    "        continue\n",
    "\n",
    "    df = read_csv_safely(src)\n",
    "\n",
    "    if \"품목명\" not in df.columns:\n",
    "        print(f\"⚠️ {src.name}: '품목명' 컬럼이 없습니다. 스킵.\")\n",
    "        continue\n",
    "\n",
    "    before = len(df)\n",
    "    df2 = df[df[\"품목명\"] != drop_value].copy()\n",
    "    after = len(df2)\n",
    "    dropped = before - after\n",
    "\n",
    "    # 새 파일명: 원본파일명 + _drop_<품목명정리>.csv\n",
    "    suffix = \"_drop_\" + sanitize_filename_piece(drop_value)\n",
    "    dst = src.with_name(src.stem + suffix + \".csv\")\n",
    "\n",
    "    df2.to_csv(dst, index=False, encoding=\"utf-8-sig\")\n",
    "    created.append(dst.name)\n",
    "\n",
    "    print(f\"✅ {src.name} → {dst.name} 저장 (총 {before}행 → {after}행, 드랍 {dropped}행: '{drop_value}')\")\n",
    "\n",
    "if created:\n",
    "    print(\"\\n생성된 파일:\")\n",
    "    for name in created:\n",
    "        print(\" -\", name)\n",
    "else:\n",
    "    print(\"\\n새로 생성된 파일이 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc70ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 브로콜리_(일반제외).csv → 브로콜리_(일반제외)_drop_브로콜리일반.csv 저장 | 10626→7084행 (드랍 3542행)\n",
      "✅ 표고버섯_cleaned.csv → 표고버섯_cleaned_drop_생표고수입.csv 저장 | 7084→3542행 (드랍 3542행)\n",
      "\n",
      "생성된 파일 목록:\n",
      " - 브로콜리_(일반제외)_drop_브로콜리일반.csv\n",
      " - 표고버섯_cleaned_drop_생표고수입.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata, re\n",
    "\n",
    "# ===== 경로 =====\n",
    "FOLDER = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종\")\n",
    "\n",
    "# ===== 유틸: 품목명 정규화 =====\n",
    "def norm_name(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    # Unicode 정규화 + BOM/제로폭문자 제거\n",
    "    s = unicodedata.normalize(\"NFKC\", str(s)).replace(\"\\ufeff\", \"\").replace(\"\\u200b\",\"\").replace(\"\\u200c\",\"\")\n",
    "    # 괄호 통일\n",
    "    s = s.replace(\"（\",\"(\").replace(\"）\",\")\").replace(\"[\",\"(\").replace(\"]\",\")\").replace(\"{\",\"(\").replace(\"}\",\")\")\n",
    "    # 전부 소문자화 + 공백 제거\n",
    "    s = re.sub(r\"\\s+\", \"\", s.lower())\n",
    "    return s\n",
    "\n",
    "# ===== 처리 규칙 (브로콜리 + 표고버섯) =====\n",
    "rules = [\n",
    "    {\n",
    "        \"file_keywords\": [\"브로콜리\", \"브로코리\"],   # 파일명 검색용\n",
    "        \"drop_values\":  [\"브로콜리(일반)\", \"브로코리(일반)\"],  # 드랍할 품목 후보\n",
    "        \"suffix\":       \"drop_브로콜리일반\"\n",
    "    },\n",
    "    {\n",
    "        \"file_keywords\": [\"표고버섯\", \"표고\"],\n",
    "        \"drop_values\":  [\"생표고(수입)\", \"생 표고(수입)\", \"생표고(수입산)\"],\n",
    "        \"suffix\":       \"drop_생표고수입\"\n",
    "    },\n",
    "]\n",
    "\n",
    "def find_csv(folder: Path, keywords: list[str]) -> Path | None:\n",
    "    \"\"\"폴더에서 파일명에 keyword 포함된 CSV 탐색\"\"\"\n",
    "    cands = []\n",
    "    for p in folder.glob(\"*.csv\"):\n",
    "        st = unicodedata.normalize(\"NFKC\", p.stem)\n",
    "        if any(k in st for k in keywords):\n",
    "            cands.append(p)\n",
    "    if not cands:\n",
    "        return None\n",
    "    # 'cleaned' 들어간 파일 우선, 그 다음 이름 짧은 순\n",
    "    cands.sort(key=lambda p: (\"cleaned\" not in p.stem, len(p.stem)))\n",
    "    return cands[0]\n",
    "\n",
    "def read_csv(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp949\")\n",
    "\n",
    "created = []\n",
    "\n",
    "for rule in rules:\n",
    "    src = find_csv(FOLDER, rule[\"file_keywords\"])\n",
    "    if src is None:\n",
    "        print(f\"⚠️ 파일을 찾지 못했습니다: 키워드={rule['file_keywords']}\")\n",
    "        continue\n",
    "\n",
    "    df = read_csv(src)\n",
    "    if \"품목명\" not in df.columns:\n",
    "        print(f\"⚠️ {src.name}: '품목명' 컬럼이 없어 스킵합니다.\")\n",
    "        continue\n",
    "\n",
    "    # 정규화 열 추가\n",
    "    df[\"_품목명_norm\"] = df[\"품목명\"].map(norm_name)\n",
    "\n",
    "    # 드랍 타겟 정규화 집합\n",
    "    targets_norm = {norm_name(v) for v in rule[\"drop_values\"]}\n",
    "\n",
    "    # 마스크 계산\n",
    "    drop_mask = df[\"_품목명_norm\"].isin(targets_norm)\n",
    "    before, drops = len(df), int(drop_mask.sum())\n",
    "    df2 = df.loc[~drop_mask].drop(columns=[\"_품목명_norm\"])\n",
    "    after = len(df2)\n",
    "\n",
    "    # 결과 저장\n",
    "    dst = src.with_name(f\"{src.stem}_{rule['suffix']}.csv\")\n",
    "    df2.to_csv(dst, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    created.append(dst.name)\n",
    "    print(f\"✅ {src.name} → {dst.name} 저장 | {before}→{after}행 (드랍 {drops}행)\")\n",
    "    if drops == 0:\n",
    "        print(\"   ⚠️ 드랍된 행이 없습니다. 실제 '품목명' 값을 다시 확인해보세요.\")\n",
    "\n",
    "if created:\n",
    "    print(\"\\n생성된 파일 목록:\")\n",
    "    for n in created:\n",
    "        print(\" -\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "553d6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: /Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종/대파_after_2015-10-19.csv\n",
      "   (행 10962 → 0, 10962행 드랍)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== 경로 설정 =====\n",
    "FOLDER = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종\")\n",
    "file_path = FOLDER / \"대파.csv\"\n",
    "\n",
    "# ===== CSV 불러오기 =====\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8-sig\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding=\"cp949\")\n",
    "\n",
    "# ===== 거래일자 컬럼을 datetime으로 변환 =====\n",
    "if \"거래일자\" not in df.columns:\n",
    "    raise KeyError(\"'거래일자' 컬럼이 없습니다. CSV 컬럼명을 확인하세요.\")\n",
    "\n",
    "# 문자열/숫자 → 날짜 변환\n",
    "df[\"거래일자_dt\"] = pd.to_datetime(df[\"거래일자\"].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "# ===== 필터링 (2015-10-19 이후만 남김) =====\n",
    "cutoff = pd.to_datetime(\"2015-10-19\")\n",
    "before_rows = len(df)\n",
    "df_filtered = df[df[\"거래일자_dt\"] > cutoff].drop(columns=[\"거래일자_dt\"])\n",
    "after_rows = len(df_filtered)\n",
    "\n",
    "# ===== 새 파일로 저장 =====\n",
    "new_path = FOLDER / \"대파_after_2015-10-19.csv\"\n",
    "df_filtered.to_csv(new_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"✅ 저장 완료: {new_path}\")\n",
    "print(f\"   (행 {before_rows} → {after_rows}, {before_rows - after_rows}행 드랍)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c149028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[완료] 대파.csv → /Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종_after_2015-10-19/대파.csv\n",
      "원본 행수: 10962, 보존 행수: 3542\n",
      "보존된 최소 거래일자: 2015-10-20\n",
      "보존된 품목명 목록: ['대파(일반)']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "대상: sojin/원본 전처리 최종/대파.csv\n",
    "처리:\n",
    " 1) '거래일자'가 2015-10-19 이하(≤)인 행 모두 제거 (NaT는 보존)\n",
    " 2) '품목명'이 '대파(일반)' 인 행만 보존\n",
    "결과: '원본 전처리 최종_after_2015-10-19/대파.csv'\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -------- 경로 설정 --------\n",
    "BASE_DIR = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin\")\n",
    "INPUT_DIR = BASE_DIR / \"원본 전처리 최종\"\n",
    "INPUT_PATH = INPUT_DIR / \"대파.csv\"\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"원본 전처리 최종_after_2015-10-19\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH = OUTPUT_DIR / \"대파.csv\"\n",
    "# ---------------------------\n",
    "\n",
    "CUTOFF = pd.Timestamp(\"2015-10-19\")\n",
    "\n",
    "def read_csv_any(p: Path) -> pd.DataFrame:\n",
    "    for enc in (\"utf-8-sig\", \"cp949\", \"utf-8\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, encoding=enc)\n",
    "        except Exception:\n",
    "            continue\n",
    "    raise RuntimeError(f\"[읽기 실패] {p}\")\n",
    "\n",
    "def find_date_col(df: pd.DataFrame) -> str:\n",
    "    canon = {re.sub(r\"\\s+\", \"\", str(c)): c for c in df.columns}\n",
    "    for key in (\"거래일자\", \"일자\", \"날짜\"):\n",
    "        if key in canon:\n",
    "            return canon[key]\n",
    "    for c in df.columns:\n",
    "        if re.sub(r\"\\s+\", \"\", str(c)) == \"거래일자\":\n",
    "            return c\n",
    "    raise KeyError(\"이 파일에 '거래일자' 컬럼이 없습니다.\")\n",
    "\n",
    "def main():\n",
    "    if not INPUT_PATH.exists():\n",
    "        raise SystemExit(f\"[에러] 대상 파일이 없습니다: {INPUT_PATH}\")\n",
    "\n",
    "    df = read_csv_any(INPUT_PATH)\n",
    "    date_col = find_date_col(df)\n",
    "\n",
    "    # 날짜 파싱\n",
    "    dt = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "\n",
    "    # 1) 날짜 조건: 2015-10-19 초과 or NaT\n",
    "    mask_date = dt.isna() | (dt > CUTOFF)\n",
    "\n",
    "    # 2) 품목명 조건: \"대파(일반)\" 만\n",
    "    mask_item = df[\"품목명\"] == \"대파(일반)\"\n",
    "\n",
    "    # 최종 필터\n",
    "    kept_df = df.loc[mask_date & mask_item].copy()\n",
    "\n",
    "    # 저장\n",
    "    kept_df.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 로그\n",
    "    min_after = pd.to_datetime(kept_df[date_col], errors=\"coerce\").min()\n",
    "    print(f\"[완료] {INPUT_PATH.name} → {OUTPUT_PATH}\")\n",
    "    print(f\"원본 행수: {len(df)}, 보존 행수: {len(kept_df)}\")\n",
    "    print(\"보존된 최소 거래일자:\", None if pd.isna(min_after) else str(min_after.date()))\n",
    "    print(\"보존된 품목명 목록:\", kept_df[\"품목명\"].unique())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37504e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] utf-8-sig 인코딩 실패: 'utf-8' codec can't decode byte 0xb0 in position 1: invalid start byte\n",
      "[INFO] cp949 인코딩으로 읽기 성공\n",
      "[완료] 대파.csv → /Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin/원본 전처리 최종_after_2015-10-19/대파_filtered.csv\n",
      "원본 행수: 10962, 보존 행수: 3542\n",
      "보존된 최소 거래일자: 2015-10-20 00:00:00\n",
      "보존된 품목명 목록: ['대파(일반)']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "대상: sojin/원본 전처리 최종/대파.csv\n",
    "처리:\n",
    " 1) '거래일자' <= 2015-10-19 행 제거 (NaT는 보존)\n",
    " 2) '품목명' == '대파(일반)' 만 보존\n",
    "결과: sojin/원본 전처리 최종_after_2015-10-19/대파_filtered.csv\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- 경로 설정 ----------------\n",
    "BASE_DIR = Path(\"/Users/sojinjung/Documents/GitHub/GDF_Final_G3/sojin\")\n",
    "INPUT_PATH = BASE_DIR / \"원본 전처리 최종\" / \"대파.csv\"\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"원본 전처리 최종_after_2015-10-19\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH = OUTPUT_DIR / \"대파_filtered.csv\"\n",
    "# -------------------------------------------\n",
    "\n",
    "CUTOFF = pd.Timestamp(\"2015-10-19\")\n",
    "\n",
    "# CSV 읽기 (인코딩 시도)\n",
    "for enc in (\"utf-8-sig\", \"cp949\", \"utf-8\"):\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_PATH, encoding=enc)\n",
    "        print(f\"[INFO] {enc} 인코딩으로 읽기 성공\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {enc} 인코딩 실패: {e}\")\n",
    "else:\n",
    "    raise SystemExit(f\"[에러] {INPUT_PATH} 파일 읽기 실패\")\n",
    "\n",
    "# 거래일자 컬럼 확인\n",
    "if \"거래일자\" not in df.columns:\n",
    "    raise SystemExit(\"[에러] '거래일자' 컬럼이 없습니다\")\n",
    "\n",
    "# 날짜 파싱\n",
    "df[\"거래일자\"] = pd.to_datetime(df[\"거래일자\"], errors=\"coerce\")\n",
    "\n",
    "# 조건 적용\n",
    "mask_date = df[\"거래일자\"].isna() | (df[\"거래일자\"] > CUTOFF)\n",
    "mask_item = df[\"품목명\"] == \"대파(일반)\"\n",
    "\n",
    "filtered_df = df.loc[mask_date & mask_item].copy()\n",
    "\n",
    "# 결과 저장 (데이터가 비어 있어도 저장됨)\n",
    "filtered_df.to_csv(OUTPUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 로그 출력\n",
    "print(f\"[완료] {INPUT_PATH.name} → {OUTPUT_PATH}\")\n",
    "print(f\"원본 행수: {len(df)}, 보존 행수: {len(filtered_df)}\")\n",
    "if not filtered_df.empty:\n",
    "    print(\"보존된 최소 거래일자:\", filtered_df[\"거래일자\"].min())\n",
    "    print(\"보존된 품목명 목록:\", filtered_df[\"품목명\"].unique())\n",
    "else:\n",
    "    print(\"[주의] 필터링 결과가 비어 있습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764eaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
